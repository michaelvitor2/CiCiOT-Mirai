{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar todas bibliotecas necessárias para execução do código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, r2_score, ConfusionMatrixDisplay\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro passo é extrair o CICIoT 2023, logo depois é processar o arquivo em chunks para criação do dataset com ataques de mirai e tráfego benigno que é nossa área de pesquisa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho para o arquivo grande\n",
    "file_path = \"/home/michael/Mestrado/METODOS_QT/DatasetFull/CIC_IoT_Dataset_Unificado.csv\"\n",
    "\n",
    "# Caminho para o arquivo de saída\n",
    "output_path = \"/home/michael/Mestrado/METODOS_QT/DatasetFull/CIC_IoT_Dataset_Unificado_resumido.csv\"\n",
    "\n",
    "# Tamanho do chunk\n",
    "chunk_size = 100000\n",
    "\n",
    "# Inicializar um arquivo de saída vazio\n",
    "with open(output_path, 'w') as output_file:\n",
    "    # Processar o arquivo em chunks\n",
    "    for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size)):\n",
    "        print(f\"Processando chunk {i + 1}\")\n",
    "        \n",
    "        # Filtrar dados que interessam (exemplo: manter apenas \"Mirai\" e \"BenignTraffic\")\n",
    "        filtered_chunk = chunk[\n",
    "            chunk['label'].str.contains('Mirai', regex=True) | \n",
    "            (chunk['label'] == 'BenignTraffic')\n",
    "        ]\n",
    "        \n",
    "        if i == 0:\n",
    "            # Escrever cabeçalho no primeiro chunk\n",
    "            filtered_chunk.to_csv(output_file, index=False, mode='w')\n",
    "        else:\n",
    "            # Para chunks subsequentes, não incluir cabeçalho\n",
    "            filtered_chunk.to_csv(output_file, index=False, mode='a', header=False)\n",
    "\n",
    "print(f\"Processo concluído. Dados filtrados salvos em {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregar o novo dataset gerado com o procedimento realizado acima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o novo dataset\n",
    "novo_dataset = pd.read_csv(\"/home/michael/Mestrado/METODOS_QT/DatasetFull/CIC_IoT_Dataset_Unificado_resumido.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificação das colunas categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas categóricas\n",
    "categorical_columns = novo_dataset.select_dtypes(include=['object']).columns\n",
    "print(f\"Colunas categóricas: {categorical_columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar o LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Aplicar Label Encoding às colunas categóricas\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    novo_dataset[col] = le.fit_transform(novo_dataset[col])\n",
    "    label_encoders[col] = le  # Armazenar o encoder para decodificação futura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar o ONEHOTENCONDING ***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar One-Hot Encoding\n",
    "X = pd.get_dummies(novo_dataset, columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando a existência de valores NaN no dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar colunas que possuem valores NaN (ausentes)\n",
    "nan_columns = novo_dataset.columns[novo_dataset.isnull().any()]\n",
    "\n",
    "# Exibir colunas com valores NaN e o número de valores ausentes em cada uma\n",
    "if len(nan_columns) > 0:\n",
    "    nan_info = novo_dataset[nan_columns].isnull().sum()\n",
    "    print(\"Colunas com valores NaN (ausentes):\")\n",
    "    print(nan_info)\n",
    "else:\n",
    "    print(\"Nenhuma coluna possui valores NaN no dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificação e remoção de colunas que possuem apenas o valor 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropar todas as colunas que só contenham o valor 0.0 no dataset\n",
    "zero_columns = novo_dataset.columns[(novo_dataset == 0.0).all()]\n",
    "\n",
    "if len(zero_columns) > 0:\n",
    "    print(f\"As seguintes colunas possuem apenas valores 0.0 e serão removidas: {zero_columns.tolist()}\")\n",
    "    novo_dataset = novo_dataset.drop(columns=zero_columns)\n",
    "else:\n",
    "    print(\"Nenhuma coluna contém apenas valores 0.0 no dataset.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapa de calor com todas as features após a remoção das colunas que continham apenas valores zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Gerar o mapa de calor após a exclusão das features que continham apenas valores 0.0\n",
    "\n",
    "# Recalcular a matriz de correlação\n",
    "correlation_matrix = novo_dataset.corr()\n",
    "\n",
    "# Configurar o tamanho da figura maior para melhor visualização\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Gerar o mapa de calor\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,       # Mostrar os valores no mapa\n",
    "    fmt=\".2f\",        # Formatar os valores com duas casas decimais\n",
    "    cmap=\"coolwarm\",  # Escolher a paleta de cores\n",
    "    cbar=True,        # Exibir a barra de cores\n",
    "    square=True,      # Manter células quadradas\n",
    "    annot_kws={\"size\": 8}  # Ajustar o tamanho das anotações\n",
    ")\n",
    "\n",
    "# Adicionar título e layout\n",
    "plt.title(\"Mapa de Calor - Correlação Após Exclusão de Features\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise  baixa correlação e alta correlação e valores parecidos de correlação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limite para correlação baixa com o label\n",
    "low_correlation_threshold = 0.1\n",
    "\n",
    "# Limite para alta correlação entre features\n",
    "high_correlation_threshold = 0.85\n",
    "\n",
    "# Identificar features com baixa correlação com o label\n",
    "correlation_with_label = correlation_matrix[\"label\"].drop(\"label\")\n",
    "low_correlation_features = correlation_with_label[correlation_with_label.abs() < low_correlation_threshold].index\n",
    "\n",
    "print(f\"Features com baixa correlação com o label (menor que {low_correlation_threshold}):\")\n",
    "print(low_correlation_features.tolist())\n",
    "\n",
    "# Identificar pares de features altamente correlacionadas\n",
    "high_correlation_pairs = []\n",
    "for feature in correlation_matrix.columns:\n",
    "    for other_feature in correlation_matrix.columns:\n",
    "        if feature != other_feature and abs(correlation_matrix[feature][other_feature]) > high_correlation_threshold:\n",
    "            high_correlation_pairs.append((feature, other_feature))\n",
    "\n",
    "print(\"\\nPares de features altamente correlacionadas (maior que 0.85):\")\n",
    "print(high_correlation_pairs)\n",
    "\n",
    "# Opcional: Remover features redundantes ou com baixa correlação\n",
    "features_to_remove = set(low_correlation_features)\n",
    "for pair in high_correlation_pairs:\n",
    "    # Remover apenas uma das features do par (exemplo: manter a primeira)\n",
    "    if pair[1] not in features_to_remove:\n",
    "        features_to_remove.add(pair[1])\n",
    "\n",
    "print(\"\\nFeatures sugeridas para remoção:\")\n",
    "print(features_to_remove)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remoção das features sugeridas e impressão do novo mapa de calor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover as features sugeridas do dataset\n",
    "features_to_remove = {'Radius', 'Srate', 'Max', 'AVG', 'LLC', 'DNS', 'fin_flag_number', 'IPv', \n",
    "                      'fin_count', 'Number', 'syn_flag_number', 'ICMP', 'Std', 'Weight', 'IAT', \n",
    "                      'Magnitue', 'psh_flag_number', 'ack_flag_number', 'ARP', 'Tot sum', \n",
    "                      'Rate', 'TCP', 'HTTPS', 'Tot size', 'rst_flag_number'}\n",
    "\n",
    "# Verificar se as features a serem removidas estão no dataset\n",
    "features_in_dataset = [feature for feature in features_to_remove if feature in novo_dataset.columns]\n",
    "\n",
    "# Remover as features do dataset\n",
    "novo_dataset = novo_dataset.drop(columns=features_in_dataset)\n",
    "\n",
    "# Exibir as features restantes no dataset\n",
    "print(\"Features restantes no dataset após a remoção:\")\n",
    "print(novo_dataset.columns.tolist())\n",
    "\n",
    "# Recalcular o mapa de calor com as features restantes\n",
    "correlation_matrix_updated = novo_dataset.corr()\n",
    "\n",
    "# Configurar o tamanho da figura\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Gerar o mapa de calor atualizado\n",
    "sns.heatmap(\n",
    "    correlation_matrix_updated,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    cbar=True,\n",
    "    square=True,\n",
    "    annot_kws={\"size\": 8}\n",
    ")\n",
    "\n",
    "# Adicionar título\n",
    "plt.title(\"Mapa de Calor - Correlação Após Remoção de Features Sugeridas\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de dispersão da feature Duration: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Decodificar as classes (labels) usando o LabelEncoder armazenado\n",
    "class_names = label_encoders['label'].inverse_transform(range(len(label_encoders['label'].classes_)))\n",
    "\n",
    "# Configurar o estilo e a paleta de cores\n",
    "sns.set_theme(style=\"whitegrid\")  # Aplicar um estilo mais limpo\n",
    "palette = sns.color_palette(\"husl\", len(class_names))  # Gerar cores distintas para cada classe\n",
    "\n",
    "# Criar a figura\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plotar cada categoria de tráfego separadamente\n",
    "for label, color in zip(range(len(class_names)), palette):\n",
    "    subset = novo_dataset[novo_dataset['label'] == label]\n",
    "    sns.histplot(\n",
    "        subset['Duration'], \n",
    "        kde=False,  # Remover a densidade para destacar as barras\n",
    "        label=f\"{class_names[label]}\", \n",
    "        bins=20,  # Reduzir o número de bins para barras mais largas\n",
    "        alpha=0.8, \n",
    "        color=color, \n",
    "    )\n",
    "\n",
    "# Ajustar título e rótulos\n",
    "plt.title(\"Distribuição de Duração de Tráfego por Categoria de Tráfego\", fontsize=18, fontweight='bold')\n",
    "plt.xlabel(\"Duração\", fontsize=14, labelpad=10)\n",
    "plt.ylabel(\"Frequência\", fontsize=14, labelpad=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Adicionar legenda com mais clareza\n",
    "plt.legend(\n",
    "    title=\"Categorias de Tráfego\", \n",
    "    fontsize=12, \n",
    "    title_fontsize=14, \n",
    "    loc='upper right', \n",
    "    frameon=True, \n",
    "    framealpha=0.9, \n",
    "    shadow=True\n",
    ")\n",
    "\n",
    "# Ajustar limites do gráfico para evitar sobreposição\n",
    "plt.ylim(0, None)  # Deixar o eixo Y começar em zero e ajustar automaticamente o topo\n",
    "\n",
    "# Ajustar grades para melhor visualização\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "# Aplicar layout mais compacto\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de dispersão da variável SYN_COUNT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Decodificar as classes (labels) usando o LabelEncoder armazenado\n",
    "class_names = label_encoders['label'].inverse_transform(range(len(label_encoders['label'].classes_)))\n",
    "\n",
    "# Configurar o estilo e a paleta de cores\n",
    "sns.set_theme(style=\"whitegrid\")  # Aplicar um estilo limpo\n",
    "palette = sns.color_palette(\"husl\", len(class_names))  # Paleta distinta para categorias\n",
    "\n",
    "# Criar a figura\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plotar cada categoria de tráfego separadamente\n",
    "for label, color in zip(range(len(class_names)), palette):\n",
    "    subset = novo_dataset[novo_dataset['label'] == label]\n",
    "    sns.histplot(\n",
    "        subset['syn_count'], \n",
    "        kde=False,  # Remover KDE para destacar barras\n",
    "        label=f\"{class_names[label]}\", \n",
    "        bins=50,  # Reduzir o número de bins para barras mais largas\n",
    "        alpha=0.8, \n",
    "        color=color\n",
    "    )\n",
    "\n",
    "# Ajustar título e rótulos\n",
    "plt.title(\"Distribuição de SYN_COUNT por Categoria de Tráfego\", fontsize=18, fontweight='bold')\n",
    "plt.xlabel(\"SYN_COUNT\", fontsize=14, labelpad=10)\n",
    "plt.ylabel(\"Frequência\", fontsize=14, labelpad=10)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Adicionar legenda mais visível\n",
    "plt.legend(\n",
    "    title=\"Categorias de Tráfego\", \n",
    "    fontsize=12, \n",
    "    title_fontsize=14, \n",
    "    loc='upper right', \n",
    "    frameon=True, \n",
    "    framealpha=0.9, \n",
    "    shadow=True\n",
    ")\n",
    "\n",
    "# Ajustar limites para melhorar visualização\n",
    "plt.ylim(0, None)  # Deixar o eixo Y ajustável automaticamente no topo\n",
    "\n",
    "# Adicionar grades leves para o eixo Y\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "# Aplicar layout mais compacto\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento e aplicação do modelo RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Separar as features e o label\n",
    "X_rf = novo_dataset.drop(columns=['label'])\n",
    "y_rf = novo_dataset['label']\n",
    "\n",
    "# Dividir os dados em treino, validação e teste (70% treino, 15% validação, 15% teste)\n",
    "X_train_rf, X_temp_rf, y_train_rf, y_temp_rf = train_test_split(X_rf, y_rf, test_size=0.3, stratify=y_rf, random_state=42)\n",
    "X_val_rf, X_test_rf, y_val_rf, y_test_rf = train_test_split(X_temp_rf, y_temp_rf, test_size=0.5, stratify=y_temp_rf, random_state=42)\n",
    "\n",
    "# Verificar os tamanhos dos conjuntos\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train_rf)}\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val_rf)}\")\n",
    "print(f\"Tamanho do conjunto de teste: {len(X_test_rf)}\")\n",
    "\n",
    "# Normalizar os dados com StandardScaler\n",
    "scaler_rf = StandardScaler()\n",
    "\n",
    "# Ajustar o scaler nos dados de treino e transformar os dados\n",
    "X_train_scaled_rf = scaler_rf.fit_transform(X_train_rf)\n",
    "\n",
    "# Apenas transformar (usar o scaler ajustado nos dados de treino) nos dados de validação e teste\n",
    "X_val_scaled_rf = scaler_rf.transform(X_val_rf)\n",
    "X_test_scaled_rf = scaler_rf.transform(X_test_rf)\n",
    "\n",
    "# Criar e treinar o modelo Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_scaled_rf, y_train_rf)\n",
    "\n",
    "# Fazer previsões no conjunto de validação\n",
    "y_val_pred_rf = model_rf.predict(X_val_scaled_rf)\n",
    "\n",
    "# Calcular métricas no conjunto de validação\n",
    "val_accuracy_rf = accuracy_score(y_val_rf, y_val_pred_rf)\n",
    "val_precision_rf = precision_score(y_val_rf, y_val_pred_rf, average='weighted')\n",
    "val_recall_rf = recall_score(y_val_rf, y_val_pred_rf, average='weighted')\n",
    "val_f1_rf = f1_score(y_val_rf, y_val_pred_rf, average='weighted')\n",
    "val_mse_rf = mean_squared_error(y_val_rf, y_val_pred_rf)\n",
    "val_rmse_rf = np.sqrt(val_mse_rf)\n",
    "val_r2_rf = r2_score(y_val_rf, y_val_pred_rf)\n",
    "\n",
    "# Exibir métricas de validação\n",
    "print(f\"Validação - Accuracy: {val_accuracy_rf:.4f}\")\n",
    "print(f\"Validação - Precision: {val_precision_rf:.4f}\")\n",
    "print(f\"Validação - Recall: {val_recall_rf:.4f}\")\n",
    "print(f\"Validação - F1-Score: {val_f1_rf:.4f}\")\n",
    "print(f\"Validação - MSE: {val_mse_rf:.4f}\")\n",
    "print(f\"Validação - RMSE: {val_rmse_rf:.4f}\")\n",
    "print(f\"Validação - R2-Score: {val_r2_rf:.4f}\")\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_test_pred_rf = model_rf.predict(X_test_scaled_rf)\n",
    "\n",
    "# Calcular métricas no conjunto de teste\n",
    "test_accuracy_rf = accuracy_score(y_test_rf, y_test_pred_rf)\n",
    "test_precision_rf = precision_score(y_test_rf, y_test_pred_rf, average='weighted')\n",
    "test_recall_rf = recall_score(y_test_rf, y_test_pred_rf, average='weighted')\n",
    "test_f1_rf = f1_score(y_test_rf, y_test_pred_rf, average='weighted')\n",
    "test_mse_rf = mean_squared_error(y_test_rf, y_test_pred_rf)\n",
    "test_rmse_rf = np.sqrt(test_mse_rf)\n",
    "test_r2_rf = r2_score(y_test_rf, y_test_pred_rf)\n",
    "\n",
    "# Exibir métricas de teste\n",
    "print(\"\\nConjunto de Teste:\")\n",
    "print(f\"Accuracy: {test_accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {test_precision_rf:.4f}\")\n",
    "print(f\"Recall: {test_recall_rf:.4f}\")\n",
    "print(f\"F1-Score: {test_f1_rf:.4f}\")\n",
    "print(f\"MSE: {test_mse_rf:.4f}\")\n",
    "print(f\"RMSE: {test_rmse_rf:.4f}\")\n",
    "print(f\"R2-Score: {test_r2_rf:.4f}\")\n",
    "\n",
    "# Relatório completo no conjunto de teste\n",
    "print(\"\\nClassification Report - Conjunto de Teste:\")\n",
    "print(classification_report(y_test_rf, y_test_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotagem das métricas de avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dados das métricas para validação e teste\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'MSE', 'RMSE', 'R2-Score']\n",
    "validation_scores = [val_accuracy_rf, val_precision_rf, val_recall_rf, val_f1_rf, val_mse_rf, val_rmse_rf, val_r2_rf]\n",
    "test_scores = [test_accuracy_rf, test_precision_rf, test_recall_rf, test_f1_rf, test_mse_rf, test_rmse_rf, test_r2_rf]\n",
    "\n",
    "# Criar o gráfico de barras para comparar as métricas\n",
    "x = range(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x, validation_scores, width, label='Validação', color='skyblue')\n",
    "ax.bar([p + width for p in x], test_scores, width, label='Teste', color='orange')\n",
    "\n",
    "# Adicionar rótulos e título\n",
    "ax.set_xlabel('Métricas')\n",
    "ax.set_ylabel('Valores')\n",
    "ax.set_title('Comparação de Métricas - Validação vs Teste')\n",
    "ax.set_xticks([p + width/2 for p in x])\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "# Adicionar rótulos nos topos das barras\n",
    "for i in range(len(x)):\n",
    "    ax.text(i, validation_scores[i], f\"{validation_scores[i]:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "    ax.text(i + width, test_scores[i], f\"{test_scores[i]:.4f}\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotagem da matriz de confusão RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recuperar o LabelEncoder do dicionário label_encoders\n",
    "# Supondo que o nome da coluna original do label é 'label'\n",
    "le_label = label_encoders['label']\n",
    "\n",
    "# Gerar a matriz de confusão para o modelo Random Forest\n",
    "conf_matrix_rf = confusion_matrix(y_test_rf, y_test_pred_rf)\n",
    "\n",
    "# Recuperar os nomes originais das classes para o Random Forest\n",
    "class_names_rf = [str(label) for label in le_label.inverse_transform(range(len(le_label.classes_)))]\n",
    "\n",
    "# Exibir a matriz de confusão para o modelo LightGBM\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_rf, display_labels=class_names_rf)\n",
    "disp_rf.plot(cmap=\"Blues\", xticks_rotation='vertical', values_format=\".0f\")\n",
    "\n",
    "# Adicionar título\n",
    "plt.title(\"Matriz de Confusão - Random Forest\", fontsize=16)\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicação do modelo LIGHTGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Separar colunas categóricas e numéricas\n",
    "categorical_columns = ['Protocol Type']  # Adicione todas as colunas categóricas aqui\n",
    "numerical_columns = [col for col in novo_dataset.columns if col not in categorical_columns + ['label']]\n",
    "\n",
    "# Aplicar Label Encoding às colunas categóricas\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    novo_dataset[col] = le.fit_transform(novo_dataset[col])\n",
    "\n",
    "# Normalizar os dados numéricos\n",
    "scaler = StandardScaler()\n",
    "novo_dataset[numerical_columns] = scaler.fit_transform(novo_dataset[numerical_columns])\n",
    "\n",
    "# Garantir que X e y estão definidos corretamente\n",
    "X_lightgbm = novo_dataset.drop(columns=['label'])\n",
    "y_lightgbm = novo_dataset['label']\n",
    "\n",
    "# Codificar os rótulos (label)\n",
    "label_encoder_lgbm = LabelEncoder()\n",
    "y_lightgbm_encoded = label_encoder_lgbm.fit_transform(y_lightgbm)\n",
    "\n",
    "# Dividir os dados em treino, validação e teste\n",
    "X_train_lgbm, X_temp_lgbm, y_train_lgbm, y_temp_lgbm = train_test_split(X_lightgbm, y_lightgbm_encoded, test_size=0.3, stratify=y_lightgbm_encoded, random_state=42)\n",
    "X_val_lgbm, X_test_lgbm, y_val_lgbm, y_test_lgbm = train_test_split(X_temp_lgbm, y_temp_lgbm, test_size=0.5, stratify=y_temp_lgbm, random_state=42)\n",
    "\n",
    "# Criar datasets do LightGBM\n",
    "train_data_lgbm = lgb.Dataset(X_train_lgbm, label=y_train_lgbm)\n",
    "val_data_lgbm = lgb.Dataset(X_val_lgbm, label=y_val_lgbm, reference=train_data_lgbm)\n",
    "\n",
    "# Parâmetros do modelo LightGBM\n",
    "params_lgbm = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(label_encoder_lgbm.classes_),\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'multi_logloss',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Treinar o modelo LightGBM\n",
    "model_lgbm = lgb.train(\n",
    "    params_lgbm,\n",
    "    train_data_lgbm,\n",
    "    valid_sets=[val_data_lgbm],\n",
    "    num_boost_round=100\n",
    ")\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_test_pred_proba_lgbm = model_lgbm.predict(X_test_lgbm)\n",
    "y_test_pred_lgbm = y_test_pred_proba_lgbm.argmax(axis=1)  # Classe com maior probabilidade\n",
    "\n",
    "# Avaliar o modelo LightGBM\n",
    "accuracy_lgbm = accuracy_score(y_test_lgbm, y_test_pred_lgbm)\n",
    "precision_lgbm = precision_score(y_test_lgbm, y_test_pred_lgbm, average='weighted')\n",
    "recall_lgbm = recall_score(y_test_lgbm, y_test_pred_lgbm, average='weighted')\n",
    "f1_lgbm = f1_score(y_test_lgbm, y_test_pred_lgbm, average='weighted')\n",
    "\n",
    "# Cálculo de métricas adicionais\n",
    "mse_lgbm = mean_squared_error(y_test_lgbm, y_test_pred_lgbm)\n",
    "rmse_lgbm = mse_lgbm ** 0.5\n",
    "r2_lgbm = r2_score(y_test_lgbm, y_test_pred_lgbm)\n",
    "\n",
    "# Exibir métricas\n",
    "print(\"\\nConjunto de Teste - LightGBM:\")\n",
    "print(f\"Accuracy: {accuracy_lgbm:.4f}\")\n",
    "print(f\"Precision: {precision_lgbm:.4f}\")\n",
    "print(f\"Recall: {recall_lgbm:.4f}\")\n",
    "print(f\"F1-Score: {f1_lgbm:.4f}\")\n",
    "print(f\"MSE: {mse_lgbm:.4f}\")\n",
    "print(f\"RMSE: {rmse_lgbm:.4f}\")\n",
    "print(f\"R2-Score: {r2_lgbm:.4f}\")\n",
    "\n",
    "# Relatório de classificação\n",
    "print(\"\\nClassification Report - LightGBM:\")\n",
    "class_names_lgbm = [str(label) for label in label_encoder_lgbm.classes_]\n",
    "print(classification_report(y_test_lgbm, y_test_pred_lgbm, target_names=class_names_lgbm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas do modelo LGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dados das métricas do LightGBM no conjunto de teste\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'MSE', 'RMSE', 'R2-Score']\n",
    "values = [accuracy_lgbm, precision_lgbm, recall_lgbm, f1_lgbm, mse_lgbm, rmse_lgbm, r2_lgbm]\n",
    "\n",
    "# Configuração do gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics, values, color='skyblue')\n",
    "\n",
    "# Adicionar os valores no topo das barras\n",
    "for bar, value in zip(bars, values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{value:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Personalização do gráfico\n",
    "plt.title(\"Desempenho do Modelo LightGBM no Conjunto de Teste\", fontsize=14)\n",
    "plt.ylabel(\"Valores\", fontsize=12)\n",
    "plt.ylim(0, 1.1)  # Ajustar o limite do eixo Y\n",
    "plt.xticks(rotation=45, fontsize=11)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão LGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Gerar a matriz de confusão para o modelo LightGBM\n",
    "conf_matrix_lgb = confusion_matrix(y_test_lgbm, y_test_pred_lgbm)\n",
    "\n",
    "# Recuperar o LabelEncoder do dicionário label_encoders\n",
    "# Supondo que o nome da coluna original do label é 'label'\n",
    "le_label = label_encoders['label']\n",
    "\n",
    "# Recuperar os nomes originais das classes para o LightGBM\n",
    "class_names_lgb = [str(label) for label in le_label.inverse_transform(range(len(le_label.classes_)))]\n",
    "\n",
    "# Exibir a matriz de confusão para o modelo LightGBM\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_lgb, display_labels=class_names_lgb)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation='vertical', values_format=\".0f\")\n",
    "\n",
    "# Adicionar título\n",
    "plt.title(\"Matriz de Confusão - LightGBM\", fontsize=16)\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparação RF X LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Dados das métricas para Random Forest e LightGBM\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'R2-Score', 'MSE', 'RMSE', ]\n",
    "rf_values = [test_accuracy_rf, test_precision_rf, test_recall_rf, test_f1_rf,test_r2_rf, test_mse_rf, test_rmse_rf ]\n",
    "lgbm_values = [accuracy_lgbm, precision_lgbm, recall_lgbm, f1_lgbm, r2_lgbm, mse_lgbm, rmse_lgbm ]\n",
    "\n",
    "# Configuração do gráfico\n",
    "x = np.arange(len(metrics))  # Posições das métricas no eixo X\n",
    "width = 0.35  # Largura das barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Barras para Random Forest e LightGBM\n",
    "bars_rf = ax.bar(x - width/2, rf_values, width, label='Random Forest', color='skyblue')\n",
    "bars_lgbm = ax.bar(x + width/2, lgbm_values, width, label='LightGBM', color='orange')\n",
    "\n",
    "# Adicionar valores no topo das barras\n",
    "for bars in [bars_rf, bars_lgbm]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, height, f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Personalização do gráfico\n",
    "ax.set_title('Comparação de Desempenho: Random Forest vs LightGBM', fontsize=14)\n",
    "ax.set_ylabel('Valores', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics, fontsize=11)\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trabalho_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
